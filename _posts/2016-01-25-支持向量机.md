---
layout: post
title: 支持向量机
category: [数据科学, 机器学习]
---

支持向量机是监督学习的一种,用于解决分类问题.针对线性可分的样本集,支持向量机在欧几里得空间中划出一个超平面将样本分为两类,并且这个平面将离样本点尽可能地远,因此支持向量机具有较小的泛化误差.
<!--exerpt-->

## 数学模型

考虑欧几里得空间中的超平面
\\[
x^T\omega+b=0
\\]
其中,\\(\omega\\)是该超平面的法向量.如果样本集是线性可分的,那么可以划出两个平行的超平面分割样本集,且这两个平面间没有样本点,设这两个平面为

对任意样本,根据解析几何知识,其到超平面的距离为：
\\[
d_i=\frac{x_i^T\omega+b}{\lVert\omega\rVert_2}
\\]
如果平面能正确分类\\((x_i,y_i)\\),则有\\(y*d\gt0\\)(此处令负样本的y为-1).

支持向量机求解
\\[
\max_{\omega b}y_id_i \\\\\\
\mathtt{s.t.} y_i(x_i^T\omega+b)\geq d
\\]
因此支持向量机又被成为最大边距分类器.
事实上,\\(d\\)、\\(d_i\\)的度量是任意的,为了方便,不妨令\\(d=1\\),可以推出,此时也有\\(y_id_i=\frac1{\lVert\omega\rVert}\\).
另外,最大化问题可以转变为等价的最小化问题.
因此优化问题最终转变为:
\\[
\min_{\omega b}{\lVert\omega\rVert}^2 \\\\\\
\mathtt{s.t.} y_i(x_i^T\omega+b)\geq1, i=1,2,\cdots,n
\\]

## 优化问题

优化问题通过拉格朗日乘子法求解,即
\\[
\min_{\omega b}\max_{\lambda\geq0}\left\\{ {\lVert\omega\rVert}^2-\sum_{i=1}{\lambda_i(y_i(x_i^T\omega+b)-1})\right\\}
\\]

...(对偶问题的求解）

该问题的求解涉及到其对偶问题的求解,目前已经有许多成熟的数值计算库可以调用.

## 核函数

目前为止,我们仍然只讨论了线性可分的情况.对于线性不可分的样本集,可以通过将其映射到高维空间,进而变成线性可分的样本集.
然而,普通的映射可能会将空间维度提升到非常可怕的程度,进而增加计算的复杂度.因此引入核函数,避开在高维空间进行直接计算.

常用的核函数有：

* 高斯核
* 多项式核
* 线性核(无核函数)

## 松弛变量

...